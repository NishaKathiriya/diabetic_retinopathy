# -*- coding: utf-8 -*-
"""Diabetic Retinopathy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E1uo38rlBAQNtSbI0cHmNPbkJC4U_oQD
"""

!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!sudo apt-get update -qq 2>&1 > /dev/null
!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null
!google-drive-ocamlfuse

# Commented out IPython magic to ensure Python compatibility.
!sudo apt-get install -qq w3m # to act as web browser 
!xdg-settings set default-web-browser w3m.desktop # to set default browser
# %cd /content
!mkdir drive
# %cd drive
!mkdir MyDrive
# %cd ..
# %cd ..
!google-drive-ocamlfuse /content/drive/MyDrive

!pip install gradio
import gradio

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.image import imread
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,CSVLogger
from sklearn.metrics import classification_report,confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense, GlobalAveragePooling2D,BatchNormalization
from tensorflow.keras.preprocessing import image
from matplotlib.pyplot import rcParams
import cv2
import warnings
warnings.filterwarnings('ignore')
from tensorflow.keras.models import load_model
from tensorflow.keras import regularizers, optimizers
import gradio as gr
import tensorflow as tf 
import numpy as np
import requests
from tensorflow.keras.models import load_model

data_folder = r"/content/drive/MyDrive/diabetic retinopathy/colored_images"

train = tf.keras.preprocessing.image_dataset_from_directory(data_folder,validation_split=0.2,subset="training",
                                                            seed=100,image_size=(224, 224),batch_size=32)

valid = tf.keras.preprocessing.image_dataset_from_directory(data_folder,validation_split=0.2,subset="validation",
                                                            seed=100,image_size=(224, 224),batch_size=32)

class_names = train.class_names
print(class_names)

plt.figure(figsize=(15, 20))
for images, labels in train.take(1):
    for i in range(20):
        plt.subplot(5, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])

model = Sequential()

# Convolution + Maxpool2D Layer 
model.add(Conv2D(32,(3,3),input_shape=(224,224,3),activation='relu'))
model.add(MaxPooling2D(3,3))
model.add(Conv2D(16,(3,3),activation='relu'))
model.add(MaxPooling2D(2,2))
model.add(Flatten())

# Output layer
model.add(Dense(5,activation = 'softmax'))

# Complile the model
model.compile(optimizer="adam",loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=["accuracy"])

# Model Summary
model.summary()

hist = model.fit(train,validation_data=valid,epochs=20,verbose=2,batch_size=8)



train_datagen = ImageDataGenerator(rescale=1./255,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  validation_split=0.2, 
                                  horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)

image_shape=(224,224,3)
train_data=train_datagen.flow_from_directory(data_folder,subset="training",
                                         target_size=image_shape[:2],
                                         class_mode = 'categorical',
                                         batch_size=5,shuffle=True)

val_data=test_datagen.flow_from_directory(data_folder,
                                       subset="validation",
                                       target_size=image_shape[:2],
                                       class_mode = 'categorical',
                                       batch_size=5,shuffle=True)

model1 = Sequential()

model1.add(Conv2D(32,(3,3),input_shape=(224,224,3),activation='relu'))
model1.add(MaxPooling2D(3,3))
model1.add(Conv2D(16,(3,3),activation='relu'))
model1.add(MaxPooling2D(2,2))
model1.add(Flatten())

model1.add(Dense(5,activation = 'softmax'))

model1.compile(optimizer="adam",loss='categorical_crossentropy',metrics=["accuracy"])
model1.summary()

hist_1 = model1.fit(train_data,validation_data=val_data,epochs=10,verbose=2,batch_size=5,steps_per_epoch=len(train_data),validation_steps=len(val_data))

model2 = Sequential(name='Batch_Normalization')
model2.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=image_shape))
model2.add(MaxPool2D(pool_size=2, strides=2))
model2.add(BatchNormalization())

model2.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model2.add(MaxPool2D(pool_size=2, strides=2))
model2.add(BatchNormalization())

model2.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model2.add(MaxPool2D(pool_size=2, strides=2))
model2.add(BatchNormalization())

model2.add(Flatten())

model2.add(Dense(units=512, activation='relu'))
model2.add(Dense(units=256, activation='relu'))
model2.add(Dense(units=128, activation='relu'))
model2.add(Dense(units=5, activation='sigmoid'))
print(model2.summary())

model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

hist_2 = model2.fit_generator(train_data,
                             epochs=10,
                             verbose=2,
                             steps_per_epoch=len(train_data),
                             validation_data=val_data,
                             validation_steps=len(val_data))

model3 = Sequential(name='Dropout')
model3.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=image_shape))
model3.add(MaxPool2D(pool_size=2, strides=2))
model3.add(Dropout(0.3))

model3.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model3.add(MaxPool2D(pool_size=2, strides=2))
model3.add(Dropout(0.3))

model3.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model3.add(MaxPool2D(pool_size=2, strides=2))
model3.add(Dropout(0.3))

model3.add(Flatten())

model3.add(Dense(units=512, activation='relu'))
model3.add(Dense(units=256, activation='relu'))
model3.add(Dense(units=128, activation='relu'))
model3.add(Dense(units=5, activation='sigmoid'))
print(model.summary())

model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


hist_3 = model3.fit_generator(train_data,
                             epochs=15,
                             verbose=2,
                             steps_per_epoch=len(train_data),
                             validation_data=val_data,
                             validation_steps=len(val_data))

base_model=tf.keras.applications.MobileNet(input_shape=image_shape,include_top=False)

base_model.trainable=False

for layer in base_model.layers[71:]:
    layer.trainable=True

model_final=Sequential([base_model,
                          GlobalAveragePooling2D(),
                          Dense(512,activation='relu'),
                          Dense(5,activation='softmax')])

model_final.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss',patience=10)
check_point=ModelCheckpoint('/content/drive/MyDrive/diabetic retinopathy/Model_weights/model.{epoch:02d}-{val_loss:.2f}.h5',)
csv_logger = CSVLogger('/content/drive/MyDrive/diabetic retinopathy/training.log')

model_final.summary()

model_final.fit_generator(train_data,epochs=30,steps_per_epoch=len(train_data),validation_data=val_data,
                              validation_steps=len(val_data),verbose=2,
                              callbacks=[early_stop,check_point,csv_logger])

log=pd.read_csv('/content/drive/MyDrive/diabetic retinopathy/training.log',index_col=0)
log.sort_values(by='val_accuracy',ascending=False).head(10)

mod=load_model('/content/drive/MyDrive/diabetic retinopathy/Model_weights/model.19-0.57.h5')

model_load=mod=load_model(r"/content/drive/MyDrive/diabetic retinopathy/Model_weights/model.19-0.57.h5")
class_names=['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']

def prediction(image):
    image = image.reshape((1, 224, 224, 3))
    image=tf.keras.applications.mobilenet.preprocess_input(image)
    prediction = model_load.predict(image).flatten()
    return {class_names[i]: float(prediction[i]) for i in range(5)}

image1 = gr.inputs.Image(shape=(224,224))
label1 = gr.outputs.Label(num_top_classes=5)

# Gradio interface to input an image and see its prediction with percentage confidence
gr.Interface(fn=prediction, inputs=image1, outputs=label1,
             #theme="huggingface",
             title="Diabetic Retinopathy",
             allow_flagging=False,
             layout="vertical",
             live=True,
             capture_session=True,
             interpretation='default').launch(debug='True',share=True)

